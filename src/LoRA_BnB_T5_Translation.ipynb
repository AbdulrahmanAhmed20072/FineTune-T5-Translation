{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b5725d632df4c73be6256135336f36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b1f605b3991438383d296997b96e695",
              "IPY_MODEL_ee21828117d9422da2b3457dccf34f47",
              "IPY_MODEL_56de12b41d8a427e8475a2299d97e2a7"
            ],
            "layout": "IPY_MODEL_26f3e34e60384b5faf320995052399c3"
          }
        },
        "0b1f605b3991438383d296997b96e695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc9a773952ac41fcb3a916e049db7bbb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a192c859ad1145d9ae9bac599dfdabd7",
            "value": "Map:â€‡100%"
          }
        },
        "ee21828117d9422da2b3457dccf34f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fac0e4bf25884e068714158bdf91e9bd",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e409ba5228ca400eb79e7d79f7f2c5b3",
            "value": 800
          }
        },
        "56de12b41d8a427e8475a2299d97e2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4def46d42d4745fe851fffb34d79e7b6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8907860d4a294128a36dabe83d904805",
            "value": "â€‡800/800â€‡[00:00&lt;00:00,â€‡880.13â€‡examples/s]"
          }
        },
        "26f3e34e60384b5faf320995052399c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc9a773952ac41fcb3a916e049db7bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a192c859ad1145d9ae9bac599dfdabd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fac0e4bf25884e068714158bdf91e9bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e409ba5228ca400eb79e7d79f7f2c5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4def46d42d4745fe851fffb34d79e7b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8907860d4a294128a36dabe83d904805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ba0300d242644189df5949c59d6699b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b0a7082db6547a7a9f64defb1e1ea4f",
              "IPY_MODEL_e020c2b8c195438b9a2538c1ab5b0b49",
              "IPY_MODEL_3060a72f0e594e02b68691c0de3481ee"
            ],
            "layout": "IPY_MODEL_dbab198540d3449ab65bf42a02ced716"
          }
        },
        "0b0a7082db6547a7a9f64defb1e1ea4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea456a5234d64a90a0db782df0627d72",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_35b4e711a75445ee8990bfce179a8f0d",
            "value": "Map:â€‡100%"
          }
        },
        "e020c2b8c195438b9a2538c1ab5b0b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4636095fd57542daafaf70e7619f72e6",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37cc98d495ad40a8a1dfad959a65345c",
            "value": 200
          }
        },
        "3060a72f0e594e02b68691c0de3481ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43fdb23f868f43dc95c23da9cc44d68c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_36c837a4c10744999d2799aea5570c71",
            "value": "â€‡200/200â€‡[00:00&lt;00:00,â€‡1485.01â€‡examples/s]"
          }
        },
        "dbab198540d3449ab65bf42a02ced716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea456a5234d64a90a0db782df0627d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b4e711a75445ee8990bfce179a8f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4636095fd57542daafaf70e7619f72e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37cc98d495ad40a8a1dfad959a65345c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43fdb23f868f43dc95c23da9cc44d68c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c837a4c10744999d2799aea5570c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets==3.2.0 bitsandbytes==0.45.1 accelerate==1.2.1 evaluate==0.4.3 \\\n",
        "    transformers==4.47.1 torch==2.5.1+cu124 numpy==1.26.4 peft==0.14.0 sacrebleu"
      ],
      "metadata": {
        "id": "9TiPrCY6ovd8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    TaskType,\n",
        "    prepare_model_for_kbit_training\n",
        ")"
      ],
      "metadata": {
        "id": "vDKBQpoRoxtd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "p_rUFGtqo3R3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurations\n",
        "MODEL_NAME = \"google-t5/t5-small\"\n",
        "TRANSLATION_PREFIX = \"translate from English to French: \"\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_TRAIN_EPOCHS = 3\n",
        "LEARNING_RATE = 2e-4"
      ],
      "metadata": {
        "id": "o0jPpN7po5tv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "books = load_dataset(\"opus_books\", \"en-fr\", split = \"train[:1000]\")\n",
        "books = books.train_test_split(test_size = 0.2, seed = 42)\n",
        "books"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "poOFRtldo8oP",
        "outputId": "9378e08e-7f45-473d-c8ef-d20e0a8552e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 800\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 200\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# translation sample example\n",
        "books[\"train\"][\"translation\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QirP4kHsi0b",
        "outputId": "36451461-c1f2-4f71-f55a-d7affe17e7f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'The old lady, shaky and worn with age, never ceased chatting and laughing.',\n",
              " 'fr': 'La vieille dame, cassÃ©e, tremblante, ne cessait de causer gaiement et de rire.'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "lkDtXdKvpBoj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_function(examples):\n",
        "\n",
        "    \"\"\"\n",
        "    Preprocess the translation dataset by tokenizing inputs and targets.\n",
        "\n",
        "    Args:\n",
        "        examples (dict): Batch of translation examples\n",
        "\n",
        "    Returns:\n",
        "        dict: Tokenized model inputs\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = [TRANSLATION_PREFIX + ex[\"en\"] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        text_target = targets,\n",
        "        max_length = MAX_LENGTH,\n",
        "        truncation = True\n",
        "    )\n",
        "\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "u-GzA9fBpExB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize dataset\n",
        "tokenized_books = books.map(\n",
        "    preprocessing_function,\n",
        "    batched = True,\n",
        "    remove_columns = books[\"train\"].column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "2b5725d632df4c73be6256135336f36a",
            "0b1f605b3991438383d296997b96e695",
            "ee21828117d9422da2b3457dccf34f47",
            "56de12b41d8a427e8475a2299d97e2a7",
            "26f3e34e60384b5faf320995052399c3",
            "dc9a773952ac41fcb3a916e049db7bbb",
            "a192c859ad1145d9ae9bac599dfdabd7",
            "fac0e4bf25884e068714158bdf91e9bd",
            "e409ba5228ca400eb79e7d79f7f2c5b3",
            "4def46d42d4745fe851fffb34d79e7b6",
            "8907860d4a294128a36dabe83d904805",
            "9ba0300d242644189df5949c59d6699b",
            "0b0a7082db6547a7a9f64defb1e1ea4f",
            "e020c2b8c195438b9a2538c1ab5b0b49",
            "3060a72f0e594e02b68691c0de3481ee",
            "dbab198540d3449ab65bf42a02ced716",
            "ea456a5234d64a90a0db782df0627d72",
            "35b4e711a75445ee8990bfce179a8f0d",
            "4636095fd57542daafaf70e7619f72e6",
            "37cc98d495ad40a8a1dfad959a65345c",
            "43fdb23f868f43dc95c23da9cc44d68c",
            "36c837a4c10744999d2799aea5570c71"
          ]
        },
        "id": "UsmSQchxpIlV",
        "outputId": "760ad96e-7cde-4c25-ce9a-c5c6aa3cd04b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b5725d632df4c73be6256135336f36a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ba0300d242644189df5949c59d6699b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data collator\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer = tokenizer,\n",
        "    model = MODEL_NAME,\n",
        "    return_tensors = \"pt\"\n",
        ")"
      ],
      "metadata": {
        "id": "LEXca4eCsBlo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load evaluation metric\n",
        "metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "\n",
        "    \"\"\"\n",
        "    Postprocess predictions and labels for metric computation.\n",
        "\n",
        "    Args:\n",
        "        preds (list): Model predictions\n",
        "        labels (list): Ground truth labels\n",
        "\n",
        "    Returns:\n",
        "        tuple: Processed predictions and labels\n",
        "    \"\"\"\n",
        "\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels"
      ],
      "metadata": {
        "id": "Ecmy5KMNpNqn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Compute translation metrics.\n",
        "\n",
        "    Args:\n",
        "        eval_pred (EvalPrediction): Model predictions and labels\n",
        "\n",
        "    Returns:\n",
        "        dict: Evaluation metrics\n",
        "    \"\"\"\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    # Decode predictions and labels\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    # Convert to token IDs\n",
        "    decoded_preds = tokenizer.batch_decode(\n",
        "        preds.argmax(-1),\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    # Handle labels (replace -100 with pad token)\n",
        "    decoded_labels = tokenizer.batch_decode(\n",
        "        np.where(labels != -100, labels, tokenizer.pad_token_id), # where labels equal -100 replace with pad token\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    # Postprocess\n",
        "    decoded_preds, decoded_labels = postprocess_text(\n",
        "        decoded_preds, decoded_labels\n",
        "    )\n",
        "\n",
        "    # Compute BLEU score\n",
        "    result = metric.compute(\n",
        "        predictions = decoded_preds,\n",
        "        references = decoded_labels\n",
        "    )\n",
        "\n",
        "    # Add generation length metric\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred) for pred in preds.argmax(-1)\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"bleu\": result[\"score\"],\n",
        "        \"gen_len\": np.mean(prediction_lens),\n",
        "        \"bleu_normalized\": round(result[\"score\"], 4)\n",
        "    }"
      ],
      "metadata": {
        "id": "_Yt6P3nOpUQ1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantization configuration\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = True ,\n",
        "    bnb_4bit_compute_dtype = 'bfloat16',\n",
        "    bnb_4bit_quant_type = 'nf4',\n",
        "    bnb_4bit_use_double_quant = True ,\n",
        ")"
      ],
      "metadata": {
        "id": "1eXxJyYOppQn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load base model with quantization\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config = quantization_config,\n",
        ")\n",
        "\n",
        "# insted of storing activations in ram to be used in backword pass\n",
        "# save some and calculate the other during backword pass, this saves some memory\n",
        "base_model.gradient_checkpointing_enable()\n",
        "\n",
        "# Prepare model for k-bit training\n",
        "model = prepare_model_for_kbit_training(base_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQRubohFpqpT",
        "outputId": "349c192a-9fd3-4fd4-d1a4-a19a976c92ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find target modules for LoRA\n",
        "target_modules = set()\n",
        "for name, module in base_model.named_modules():\n",
        "    if isinstance(module, torch.nn.Linear):\n",
        "        module_name = name.split('.')[-1]\n",
        "        target_modules.add(module_name)\n",
        "target_modules = list(target_modules)\n",
        "target_modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gnc7EvxNqsNT",
        "outputId": "696ef2f7-4a37-4ab0-da84-152060ebfbdb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wo', 'q', 'lm_head', 'wi', 'o', 'k', 'v']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r = 4,\n",
        "    lora_alpha = 2,\n",
        "    lora_dropout = 0.1,\n",
        "    bias = 'none',\n",
        "    task_type = TaskType.SEQ_2_SEQ_LM,\n",
        "    target_modules = target_modules\n",
        ")\n",
        "\n",
        "# Get PEFT model\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "lora_model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGCEj8h6qug9",
        "outputId": "9d34e349-d535-4470-f497-54e2a4a0dc18"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 671,232 || all params: 61,177,856 || trainable%: 1.0972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:543: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./translation_results\",\n",
        "    overwrite_output_dir = True,\n",
        "    num_train_epochs = NUM_TRAIN_EPOCHS,\n",
        "    per_device_train_batch_size = BATCH_SIZE,\n",
        "    per_device_eval_batch_size = BATCH_SIZE,\n",
        "    learning_rate = LEARNING_RATE,\n",
        "    warmup_ratio = 0.1,\n",
        "    weight_decay = 0.01, # L2 regularization\n",
        "    logging_dir = './logs',\n",
        "    logging_strategy = 'steps',\n",
        "    logging_steps = 50,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'bleu',\n",
        "    dataloader_pin_memory = True, # data intially loadded into CPU then copied to GPU, set to True for transfer directly to GPU, it's faster\n",
        "    bf16 = True,\n",
        "    push_to_hub = False,  # Set to True if you want to push to HuggingFace Hub\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bnyoe79FqzKR",
        "outputId": "cf9829e7-7ba9-4977-f940-ff0059e14d3a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model = lora_model,\n",
        "    args = training_args,\n",
        "    train_dataset = tokenized_books['train'],\n",
        "    eval_dataset = tokenized_books['test'],\n",
        "    data_collator = data_collator,\n",
        "    compute_metrics = compute_metrics,\n",
        "    processing_class = tokenizer\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "3Tg-F8rCq1VY",
        "outputId": "c633c560-48f1-4e55-feee-f32309562d99"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabdulrahman-ahmed20072\u001b[0m (\u001b[33mabdulrahman-ahmed20072-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250204_192248-lyd441mx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abdulrahman-ahmed20072-none/huggingface/runs/lyd441mx' target=\"_blank\">./translation_results</a></strong> to <a href='https://wandb.ai/abdulrahman-ahmed20072-none/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abdulrahman-ahmed20072-none/huggingface' target=\"_blank\">https://wandb.ai/abdulrahman-ahmed20072-none/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abdulrahman-ahmed20072-none/huggingface/runs/lyd441mx' target=\"_blank\">https://wandb.ai/abdulrahman-ahmed20072-none/huggingface/runs/lyd441mx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 01:21, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Gen Len</th>\n",
              "      <th>Bleu Normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.083500</td>\n",
              "      <td>1.903999</td>\n",
              "      <td>4.936789</td>\n",
              "      <td>106.800000</td>\n",
              "      <td>4.936800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.058100</td>\n",
              "      <td>1.882716</td>\n",
              "      <td>4.983657</td>\n",
              "      <td>106.800000</td>\n",
              "      <td>4.983700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.034300</td>\n",
              "      <td>1.873490</td>\n",
              "      <td>5.061911</td>\n",
              "      <td>106.800000</td>\n",
              "      <td>5.061900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=150, training_loss=2.0586392720540365, metrics={'train_runtime': 87.5308, 'train_samples_per_second': 27.419, 'train_steps_per_second': 1.714, 'total_flos': 50135221075968.0, 'train_loss': 2.0586392720540365, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BTz7s4qpngwJ"
      },
      "outputs": [],
      "source": [
        "# Inference function\n",
        "def translate_text(text, max_length=MAX_LENGTH):\n",
        "\n",
        "    \"\"\"\n",
        "    Translate text from English to French.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to translate\n",
        "        max_length (int): Maximum length of generated translation\n",
        "\n",
        "    Returns:\n",
        "        str: Translated text\n",
        "    \"\"\"\n",
        "\n",
        "    # Prepare input\n",
        "    inputs = tokenizer(\n",
        "        TRANSLATION_PREFIX + text,\n",
        "        return_tensors = \"pt\",\n",
        "        max_length = max_length,\n",
        "        truncation = True\n",
        "    ).to(lora_model.device)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    lora_model.eval()\n",
        "\n",
        "    # Generate translation\n",
        "    with torch.no_grad():\n",
        "        outputs = lora_model.generate(\n",
        "            **inputs,\n",
        "            max_length = max_length,\n",
        "            num_return_sequences = 1,\n",
        "            do_sample = False  # Use greedy decoding\n",
        "        )\n",
        "\n",
        "    # Decode and return translation\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_text = \"Hello, how are you?\"\n",
        "\n",
        "print(f\"Original: {example_text}\")\n",
        "print(f\"Translation: {translate_text(example_text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbWTa-MMq6kW",
        "outputId": "671b5fd5-453d-4ea6-b1d7-a199190a579d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: Hello, how are you?\n",
            "Translation: Bonjour, comment Ãªtes-vous?\n"
          ]
        }
      ]
    }
  ]
}